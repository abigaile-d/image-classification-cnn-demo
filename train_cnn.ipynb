{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from lenet import LeNet\n",
    "from vgg import VGGNet\n",
    "from resnet import ResNet\n",
    "from utils import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configurable parameters, can as needed\n",
    "\n",
    "# skip if loading existing model file\n",
    "skip_training = True\n",
    "\n",
    "# choose only from: 'lenet', 'vggnet' or 'resnet'\n",
    "network_archi = 'resnet'\n",
    "assert network_archi in ('lenet', 'vggnet', 'resnet')\n",
    "\n",
    "# set data & model dir paths\n",
    "data_dir = 'data/'\n",
    "save_path = 'models/' + network_archi + '.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in cpu\n"
     ]
    }
   ],
   "source": [
    "# additional settings\n",
    "\n",
    "# set to as appropriate: on either cpu or gpu\n",
    "if skip_training:\n",
    "   device_type = 'cpu'\n",
    "elif torch.cuda.is_available():\n",
    "    device_type = 'cuda:0'\n",
    "else:\n",
    "    device_type = 'cpu'\n",
    "\n",
    "# assign device\n",
    "device = torch.device(device_type)\n",
    "print(\"Running in {}\".format(device_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the network based on selected network archi type\n",
    "\n",
    "if network_archi == 'lenet':\n",
    "    net = LeNet(1, 10)\n",
    "elif network_archi == 'vggnet':\n",
    "    net = VGGNet(1, 10)\n",
    "elif network_archi == 'resnet':\n",
    "    net = ResNet(1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare dataset\n",
    "\n",
    "# list image transformations to perform\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # transform to tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))  # scale to [-1, 1]\n",
    "])\n",
    "\n",
    "# load fashion mnist dataset (available in torch)\n",
    "trainset = torchvision.datasets.FashionMNIST(root=data_dir, train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.FashionMNIST(root=data_dir, train=False, download=True, transform=transform)\n",
    "classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "# use dataloader to load and iterate on dataset easily\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run training by calling the training method from utils\n",
    "\n",
    "if not skip_training:\n",
    "    train = Trainer(net, trainloader, testloader, device_type, archi_type=network_archi)\n",
    "    train.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "\n",
    "if not skip_training:\n",
    "    torch.save(net.state_dict(), save_path)\n",
    "    print('Model saved to: {}'.format(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from: models/resnet.pth\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "if skip_training:\n",
    "    net.load_state_dict(torch.load(save_path, map_location=lambda storage, loc: storage))\n",
    "    print('Model loaded from: {}'.format(save_path))\n",
    "    net.to(device)\n",
    "    net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 0.9275\n"
     ]
    }
   ],
   "source": [
    "# evaluate and compute accuracy\n",
    "\n",
    "if skip_training:\n",
    "    train = Trainer(net, trainloader, testloader, device)\n",
    "accuracy = train.test()\n",
    "print('Accuracy of the network on the test images: {}'.format(accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops_projs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
